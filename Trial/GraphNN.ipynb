{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Graph NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_a</th>\n",
       "      <th>paper_b</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>category_0</th>\n",
       "      <th>...</th>\n",
       "      <th>category_26_b</th>\n",
       "      <th>category_27_b</th>\n",
       "      <th>category_28_b</th>\n",
       "      <th>category_29_b</th>\n",
       "      <th>category_30_b</th>\n",
       "      <th>category_31_b</th>\n",
       "      <th>category_32_b</th>\n",
       "      <th>category_33_b</th>\n",
       "      <th>category_34_b</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>613474</td>\n",
       "      <td>427450</td>\n",
       "      <td>0</td>\n",
       "      <td>Journalism in the Digital Age: Theory and Prac...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>613474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429899</td>\n",
       "      <td>103315</td>\n",
       "      <td>0</td>\n",
       "      <td>OM-based video shot retrieval by one-to-one ma...</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>429899</td>\n",
       "      <td>313719;325068;537557</td>\n",
       "      <td>This paper proposes a new approach for shot-ba...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>150048</td>\n",
       "      <td>357500</td>\n",
       "      <td>0</td>\n",
       "      <td>Reasoning about action II: the qualification p...</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>150048</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>318445</td>\n",
       "      <td>405309</td>\n",
       "      <td>0</td>\n",
       "      <td>COMIT as an IR language</td>\n",
       "      <td>1962</td>\n",
       "      <td>1</td>\n",
       "      <td>318445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>313668</td>\n",
       "      <td>326368</td>\n",
       "      <td>1</td>\n",
       "      <td>A preliminary system for the design of DBTG da...</td>\n",
       "      <td>1975</td>\n",
       "      <td>1</td>\n",
       "      <td>313668</td>\n",
       "      <td>196297;326368</td>\n",
       "      <td>The functional approach to database design is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.145828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_a paper_b  label                                              title  \\\n",
       "0  613474  427450      0  Journalism in the Digital Age: Theory and Prac...   \n",
       "1  429899  103315      0  OM-based video shot retrieval by one-to-one ma...   \n",
       "2  150048  357500      0  Reasoning about action II: the qualification p...   \n",
       "3  318445  405309      0                            COMIT as an IR language   \n",
       "4  313668  326368      1  A preliminary system for the design of DBTG da...   \n",
       "\n",
       "   year  venue   index             citations  \\\n",
       "0  2000      1  613474                   NaN   \n",
       "1  2007      1  429899  313719;325068;537557   \n",
       "2  1988      1  150048                   NaN   \n",
       "3  1962      1  318445                   NaN   \n",
       "4  1975      1  313668         196297;326368   \n",
       "\n",
       "                                            abstract  category_0  ...  \\\n",
       "0                                                NaN           0  ...   \n",
       "1  This paper proposes a new approach for shot-ba...           0  ...   \n",
       "2                                                NaN           0  ...   \n",
       "3                                                NaN           0  ...   \n",
       "4  The functional approach to database design is ...           0  ...   \n",
       "\n",
       "   category_26_b  category_27_b  category_28_b  category_29_b  category_30_b  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   category_31_b  category_32_b  category_33_b  category_34_b  \\\n",
       "0              0              0              0              1   \n",
       "1              0              0              0              0   \n",
       "2              0              0              0              1   \n",
       "3              0              0              0              1   \n",
       "4              0              0              0              0   \n",
       "\n",
       "   title_similarity  \n",
       "0          0.000000  \n",
       "1          0.000000  \n",
       "2          0.000000  \n",
       "3          0.000000  \n",
       "4          0.145828  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_a</th>\n",
       "      <th>paper_b</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>category_0</th>\n",
       "      <th>...</th>\n",
       "      <th>category_26_b</th>\n",
       "      <th>category_27_b</th>\n",
       "      <th>category_28_b</th>\n",
       "      <th>category_29_b</th>\n",
       "      <th>category_30_b</th>\n",
       "      <th>category_31_b</th>\n",
       "      <th>category_32_b</th>\n",
       "      <th>category_33_b</th>\n",
       "      <th>category_34_b</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>305306</td>\n",
       "      <td>482357</td>\n",
       "      <td>0</td>\n",
       "      <td>A temporal data model and management system fo...</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>305306</td>\n",
       "      <td>221485;298302;571065;356287;364404;379562;5654...</td>\n",
       "      <td>In this paper,we present the results of an on-...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>280356</td>\n",
       "      <td>282276</td>\n",
       "      <td>1</td>\n",
       "      <td>Extractors and pseudo-random generators with o...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>280356</td>\n",
       "      <td>82934;144784;241111;599315;283217;486962;28227...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>46485</td>\n",
       "      <td>116944</td>\n",
       "      <td>1</td>\n",
       "      <td>Accelerated parallel texture optimization</td>\n",
       "      <td>2007</td>\n",
       "      <td>1</td>\n",
       "      <td>46485</td>\n",
       "      <td>116944;285389;319592;235532;620027;600250;95085</td>\n",
       "      <td>Texture optimization is a texture synthesis me...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>432786</td>\n",
       "      <td>317771</td>\n",
       "      <td>1</td>\n",
       "      <td>NPS: a non-interfering deployable web perfectc...</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>432786</td>\n",
       "      <td>290698;316863;317771;321745;613647</td>\n",
       "      <td>We present NPS, a novel non-intrusive web pref...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>576398</td>\n",
       "      <td>625796</td>\n",
       "      <td>0</td>\n",
       "      <td>Review of \"Berkely Transposed File Statistical...</td>\n",
       "      <td>1972</td>\n",
       "      <td>1</td>\n",
       "      <td>576398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_a paper_b  label                                              title  \\\n",
       "0  305306  482357      0  A temporal data model and management system fo...   \n",
       "1  280356  282276      1  Extractors and pseudo-random generators with o...   \n",
       "2   46485  116944      1          Accelerated parallel texture optimization   \n",
       "3  432786  317771      1  NPS: a non-interfering deployable web perfectc...   \n",
       "4  576398  625796      0  Review of \"Berkely Transposed File Statistical...   \n",
       "\n",
       "   year  venue   index                                          citations  \\\n",
       "0  2003      1  305306  221485;298302;571065;356287;364404;379562;5654...   \n",
       "1  2000      1  280356  82934;144784;241111;599315;283217;486962;28227...   \n",
       "2  2007      1   46485    116944;285389;319592;235532;620027;600250;95085   \n",
       "3  2003      1  432786                 290698;316863;317771;321745;613647   \n",
       "4  1972      1  576398                                                NaN   \n",
       "\n",
       "                                            abstract  category_0  ...  \\\n",
       "0  In this paper,we present the results of an on-...           0  ...   \n",
       "1                                                NaN           0  ...   \n",
       "2  Texture optimization is a texture synthesis me...           0  ...   \n",
       "3  We present NPS, a novel non-intrusive web pref...           0  ...   \n",
       "4                                                NaN           0  ...   \n",
       "\n",
       "   category_26_b  category_27_b  category_28_b  category_29_b  category_30_b  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   category_31_b  category_32_b  category_33_b  category_34_b  \\\n",
       "0              0              0              0              0   \n",
       "1              0              0              0              1   \n",
       "2              0              0              0              1   \n",
       "3              0              0              0              0   \n",
       "4              0              0              0              0   \n",
       "\n",
       "   title_similarity  \n",
       "0          0.000000  \n",
       "1          0.000000  \n",
       "2          0.260206  \n",
       "3          0.090369  \n",
       "4          0.012586  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_pickle('Data/train_dataset_title_sim.pkl')\n",
    "test_data = pd.read_pickle('Data/test_dataset_title_sim.pkl')\n",
    "train_labels = train_data['label']\n",
    "test_labels = test_data['label']\n",
    "\n",
    "# Display the first few rows of the training and testing datasets\n",
    "print(\"Training Data:\")\n",
    "display(train_data.head())\n",
    "print(\"\\nTesting Data:\")\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming train_data and test_data are already defined DataFrames\n",
    "\n",
    "# Function to create a balanced dataset\n",
    "def create_balanced_dataset(data, n_per_class=500):\n",
    "    # Separate the data into two groups based on the 'label'\n",
    "    group_0 = data[data['label'] == 0]\n",
    "    group_1 = data[data['label'] == 1]\n",
    "\n",
    "    # Randomly sample n_per_class rows from each group\n",
    "    sampled_group_0 = group_0.sample(n=n_per_class, random_state=55)  # Set random_state for reproducibility\n",
    "    sampled_group_1 = group_1.sample(n=n_per_class, random_state=55)\n",
    "\n",
    "    # Combine the sampled groups to create a balanced dataset\n",
    "    balanced_data = pd.concat([sampled_group_0, sampled_group_1])\n",
    "    \n",
    "    return balanced_data\n",
    "\n",
    "# # Create balanced training dataset\n",
    "# balanced_train_data = create_balanced_dataset(train_data, n_per_class=500)\n",
    "\n",
    "# # Drop the specified columns from the training dataset\n",
    "# X_train = balanced_train_data.drop(columns=['title', 'abstract', 'citations', 'index', 'label'])\n",
    "# y_train = balanced_train_data['label']\n",
    "\n",
    "# # Create balanced testing dataset\n",
    "# balanced_test_data = create_balanced_dataset(test_data, n_per_class=500)\n",
    "\n",
    "# # Drop the specified columns from the testing dataset\n",
    "# X_test = balanced_test_data.drop(columns=['title', 'abstract', 'citations', 'index', 'label'])\n",
    "# y_test = balanced_test_data['label']\n",
    "\n",
    "# # Display the first few rows of the training and testing datasets\n",
    "# print(\"Training Data:\")\n",
    "# display(X_train)\n",
    "\n",
    "# print(\"Testing Data:\")\n",
    "# display(X_test)\n",
    "\n",
    "# # Optionally, check the balance of the labels in the training and testing sets\n",
    "# print(\"Label distribution in training data:\")\n",
    "# print(y_train.value_counts())\n",
    "\n",
    "# print(\"Label distribution in testing data:\")\n",
    "# print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def create_graph(pairs_df):\n",
    "    G = nx.DiGraph()  # Directed graph\n",
    "    for _, row in pairs_df.iterrows():\n",
    "        # Add nodes for paper_a and paper_b\n",
    "        G.add_node(row['paper_a'], features=row[['year'] + ['venue'] + [f'category_{i}' for i in range(35)]].to_dict())\n",
    "        G.add_node(row['paper_b'], features=row[['year_b'] + ['venue_b'] + [f'category_{i}_b' for i in range(35)]].to_dict())\n",
    "        \n",
    "        # Add edge from paper_a to paper_b\n",
    "        G.add_edge(row['paper_a'], row['paper_b'], label=row['label'])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Create training and testing graphs\n",
    "# train_graph = create_graph(train_data)\n",
    "# test_graph = create_graph(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(train_graph.nodes), len(train_graph.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load and Prepare Data\n",
    "train_data = pd.read_pickle('Data/train_dataset_title_sim.pkl')\n",
    "test_data = pd.read_pickle('Data/test_dataset_title_sim.pkl')\n",
    "\n",
    "X_train_raw = train_data.drop(columns=['title', 'title_b', 'abstract', 'abstract_b', 'citations', 'citations_b', 'index', 'index_b', 'label'])\n",
    "y_train = train_data['label']\n",
    "X_test_raw = test_data.drop(columns=['title', 'title_b', 'abstract', 'abstract_b', 'citations', 'citations_b', 'index', 'index_b', 'label'])\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_a', 'paper_b', 'year', 'venue', 'category_0', 'category_1',\n",
       "       'category_2', 'category_3', 'category_4', 'category_5', 'category_6',\n",
       "       'category_7', 'category_8', 'category_9', 'category_10', 'category_11',\n",
       "       'category_12', 'category_13', 'category_14', 'category_15',\n",
       "       'category_16', 'category_17', 'category_18', 'category_19',\n",
       "       'category_20', 'category_21', 'category_22', 'category_23',\n",
       "       'category_24', 'category_25', 'category_26', 'category_27',\n",
       "       'category_28', 'category_29', 'category_30', 'category_31',\n",
       "       'category_32', 'category_33', 'category_34', 'year_b', 'venue_b',\n",
       "       'category_0_b', 'category_1_b', 'category_2_b', 'category_3_b',\n",
       "       'category_4_b', 'category_5_b', 'category_6_b', 'category_7_b',\n",
       "       'category_8_b', 'category_9_b', 'category_10_b', 'category_11_b',\n",
       "       'category_12_b', 'category_13_b', 'category_14_b', 'category_15_b',\n",
       "       'category_16_b', 'category_17_b', 'category_18_b', 'category_19_b',\n",
       "       'category_20_b', 'category_21_b', 'category_22_b', 'category_23_b',\n",
       "       'category_24_b', 'category_25_b', 'category_26_b', 'category_27_b',\n",
       "       'category_28_b', 'category_29_b', 'category_30_b', 'category_31_b',\n",
       "       'category_32_b', 'category_33_b', 'category_34_b', 'title_similarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7682\n",
      "Epoch 10, Loss: 0.6239\n",
      "Epoch 20, Loss: 0.5951\n",
      "Epoch 30, Loss: 0.5823\n",
      "Epoch 40, Loss: 0.5743\n",
      "Epoch 50, Loss: 0.5672\n",
      "Epoch 60, Loss: 0.5608\n",
      "Epoch 70, Loss: 0.5551\n",
      "Epoch 80, Loss: 0.5503\n",
      "Epoch 90, Loss: 0.5468\n",
      "Epoch 100, Loss: 0.5446\n",
      "Epoch 110, Loss: 0.5429\n",
      "Epoch 120, Loss: 0.5416\n",
      "Epoch 130, Loss: 0.5405\n",
      "Epoch 140, Loss: 0.5396\n",
      "Epoch 150, Loss: 0.5387\n",
      "Epoch 160, Loss: 0.5380\n",
      "Epoch 170, Loss: 0.5373\n",
      "Epoch 180, Loss: 0.5366\n",
      "Epoch 190, Loss: 0.5360\n",
      "Epoch 200, Loss: 0.5355\n",
      "Epoch 210, Loss: 0.5351\n",
      "Epoch 220, Loss: 0.5347\n",
      "Epoch 230, Loss: 0.5342\n",
      "Epoch 240, Loss: 0.5339\n",
      "Epoch 250, Loss: 0.5335\n",
      "Epoch 260, Loss: 0.5331\n",
      "Epoch 270, Loss: 0.5327\n",
      "Epoch 280, Loss: 0.5323\n",
      "Epoch 290, Loss: 0.5319\n",
      "Epoch 300, Loss: 0.5315\n",
      "Epoch 310, Loss: 0.5312\n",
      "Epoch 320, Loss: 0.5309\n",
      "Epoch 330, Loss: 0.5305\n",
      "Epoch 340, Loss: 0.5302\n",
      "Epoch 350, Loss: 0.5299\n",
      "Epoch 360, Loss: 0.5297\n",
      "Epoch 370, Loss: 0.5294\n",
      "Epoch 380, Loss: 0.5292\n",
      "Epoch 390, Loss: 0.5289\n",
      "Epoch 400, Loss: 0.5287\n",
      "Epoch 410, Loss: 0.5284\n",
      "Epoch 420, Loss: 0.5281\n",
      "Epoch 430, Loss: 0.5278\n",
      "Epoch 440, Loss: 0.5274\n",
      "Epoch 450, Loss: 0.5271\n",
      "Epoch 460, Loss: 0.5268\n",
      "Epoch 470, Loss: 0.5266\n",
      "Epoch 480, Loss: 0.5264\n",
      "Epoch 490, Loss: 0.5261\n",
      "Epoch 500, Loss: 0.5258\n",
      "Epoch 510, Loss: 0.5255\n",
      "Epoch 520, Loss: 0.5252\n",
      "Epoch 530, Loss: 0.5249\n",
      "Epoch 540, Loss: 0.5246\n",
      "Epoch 550, Loss: 0.5242\n",
      "Epoch 560, Loss: 0.5238\n",
      "Epoch 570, Loss: 0.5234\n",
      "Epoch 580, Loss: 0.5230\n",
      "Epoch 590, Loss: 0.5227\n",
      "Epoch 600, Loss: 0.5223\n",
      "Epoch 610, Loss: 0.5221\n",
      "Epoch 620, Loss: 0.5217\n",
      "Epoch 630, Loss: 0.5214\n",
      "Epoch 640, Loss: 0.5215\n",
      "Epoch 650, Loss: 0.5210\n",
      "Epoch 660, Loss: 0.5208\n",
      "Epoch 670, Loss: 0.5207\n",
      "Epoch 680, Loss: 0.5205\n",
      "Epoch 690, Loss: 0.5204\n",
      "Epoch 700, Loss: 0.5203\n",
      "Epoch 710, Loss: 0.5202\n",
      "Epoch 720, Loss: 0.5201\n",
      "Epoch 730, Loss: 0.5200\n",
      "Epoch 740, Loss: 0.5199\n",
      "Epoch 750, Loss: 0.5198\n",
      "Epoch 760, Loss: 0.5197\n",
      "Epoch 770, Loss: 0.5196\n",
      "Epoch 780, Loss: 0.5198\n",
      "Epoch 790, Loss: 0.5194\n",
      "Epoch 800, Loss: 0.5193\n",
      "Epoch 810, Loss: 0.5192\n",
      "Epoch 820, Loss: 0.5191\n",
      "Epoch 830, Loss: 0.5191\n",
      "Epoch 840, Loss: 0.5190\n",
      "Epoch 850, Loss: 0.5189\n",
      "Epoch 860, Loss: 0.5188\n",
      "Epoch 870, Loss: 0.5187\n",
      "Epoch 880, Loss: 0.5187\n",
      "Epoch 890, Loss: 0.5186\n",
      "Epoch 900, Loss: 0.5185\n",
      "Epoch 910, Loss: 0.5184\n",
      "Epoch 920, Loss: 0.5184\n",
      "Epoch 930, Loss: 0.5183\n",
      "Epoch 940, Loss: 0.5183\n",
      "Epoch 950, Loss: 0.5182\n",
      "Epoch 960, Loss: 0.5181\n",
      "Epoch 970, Loss: 0.5181\n",
      "Epoch 980, Loss: 0.5182\n",
      "Epoch 990, Loss: 0.5180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "# Step 1: Define the function to create edge indices\n",
    "def create_edge_index(data, num_nodes):\n",
    "    # Create a mapping from unique paper IDs to numeric IDs\n",
    "    paper_ids = pd.concat([data['paper_a'], data['paper_b']]).unique()\n",
    "    paper_id_map = {paper: idx for idx, paper in enumerate(paper_ids)}\n",
    "\n",
    "    edge_index = []\n",
    "    for _, row in data.iterrows():\n",
    "        if row['label'] == 1:  # Add an edge if there's a citation\n",
    "            paper_a_id = paper_id_map.get(row['paper_a'])\n",
    "            paper_b_id = paper_id_map.get(row['paper_b'])\n",
    "            if paper_a_id is not None and paper_b_id is not None:\n",
    "                # Ensure indices are within bounds\n",
    "                if paper_a_id < num_nodes and paper_b_id < num_nodes:\n",
    "                    edge_index.append([paper_a_id, paper_b_id])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Validate that all indices are within bounds\n",
    "    if edge_index.numel() > 0 and edge_index.max().item() >= num_nodes:\n",
    "        raise ValueError(\"Edge index contains out-of-bound indices!\")\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "# Step 2: Prepare edge indices\n",
    "num_nodes_train = X_train.shape[0]\n",
    "num_nodes_test = X_test.shape[0]\n",
    "\n",
    "edge_index_train = create_edge_index(train_data, num_nodes=num_nodes_train)\n",
    "edge_index_test = create_edge_index(test_data, num_nodes=num_nodes_test)\n",
    "\n",
    "# Step 3: Prepare PyTorch Geometric Data Objects\n",
    "data_train = Data(\n",
    "    x=torch.tensor(X_train, dtype=torch.float),\n",
    "    edge_index=edge_index_train,\n",
    "    y=torch.tensor(y_train.values, dtype=torch.float)\n",
    ")\n",
    "\n",
    "data_test = Data(\n",
    "    x=torch.tensor(X_test, dtype=torch.float),\n",
    "    edge_index=edge_index_test,\n",
    "    y=torch.tensor(y_test.values, dtype=torch.float)\n",
    ")\n",
    "\n",
    "# Step 4: Define the GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 1)  # Binary output\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return torch.sigmoid(x).squeeze()  # Binary probability output\n",
    "\n",
    "# Step 5: Train the GCN Model\n",
    "def train_model(model, data, epochs=1000, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.binary_cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "# Step 6: Initialize and train GCN\n",
    "gcn = GCN(num_node_features=X_train.shape[1])\n",
    "gcn = train_model(gcn, data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GCN:\n",
      "Accuracy: 0.7277\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate GCN Model\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        predictions = (out > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        accuracy = (predictions == data.y).sum().item() / len(data.y)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        return predictions\n",
    "\n",
    "print(\"\\nEvaluating GCN:\")\n",
    "gcn_predictions = evaluate_model(gcn, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "# Check if CUDA is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class ImprovedGCN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, hidden_units=64, dropout_rate=0.5):\n",
    "        super(ImprovedGCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(num_node_features, hidden_units)\n",
    "        self.conv2 = GCNConv(hidden_units, hidden_units)\n",
    "        self.conv3 = GCNConv(hidden_units, num_classes)  # Third layer\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        return torch.sigmoid(x)  # Use sigmoid for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, epochs=100, lr=0.01, patience=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data).squeeze()  # Squeeze to match the shape of the labels\n",
    "        loss = F.binary_cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Early stopping check\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter > patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data).squeeze()  # Squeeze to match the labels shape\n",
    "        pred = (out > 0.5).float()  # Convert to binary predictions (0 or 1)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        accuracy = (pred == data.y).sum().item() / len(data.y)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        return out, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the Improved GCN\n",
    "#gcn = ImprovedGCN(num_node_features=X_train.shape[1], num_classes=1)\n",
    "#gcn = train_model(gcn, data_train, epochs=1000, lr=0.005, patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GCN:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating GCN:\")\n",
    "#gcn_predictions = evaluate_model(gcn, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load and Prepare Data\n",
    "train_data = pd.read_pickle('Data/train_dataset_title_sim.pkl')\n",
    "test_data = pd.read_pickle('Data/test_dataset_title_sim.pkl')\n",
    "\n",
    "# Extracting the label column\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['paper_a', 'paper_b', 'label', 'title', 'year', 'venue', 'index',\n",
       "        'citations', 'abstract', 'category_0', 'category_1', 'category_2',\n",
       "        'category_3', 'category_4', 'category_5', 'category_6', 'category_7',\n",
       "        'category_8', 'category_9', 'category_10', 'category_11', 'category_12',\n",
       "        'category_13', 'category_14', 'category_15', 'category_16',\n",
       "        'category_17', 'category_18', 'category_19', 'category_20',\n",
       "        'category_21', 'category_22', 'category_23', 'category_24',\n",
       "        'category_25', 'category_26', 'category_27', 'category_28',\n",
       "        'category_29', 'category_30', 'category_31', 'category_32',\n",
       "        'category_33', 'category_34', 'title_b', 'year_b', 'venue_b', 'index_b',\n",
       "        'citations_b', 'abstract_b', 'category_0_b', 'category_1_b',\n",
       "        'category_2_b', 'category_3_b', 'category_4_b', 'category_5_b',\n",
       "        'category_6_b', 'category_7_b', 'category_8_b', 'category_9_b',\n",
       "        'category_10_b', 'category_11_b', 'category_12_b', 'category_13_b',\n",
       "        'category_14_b', 'category_15_b', 'category_16_b', 'category_17_b',\n",
       "        'category_18_b', 'category_19_b', 'category_20_b', 'category_21_b',\n",
       "        'category_22_b', 'category_23_b', 'category_24_b', 'category_25_b',\n",
       "        'category_26_b', 'category_27_b', 'category_28_b', 'category_29_b',\n",
       "        'category_30_b', 'category_31_b', 'category_32_b', 'category_33_b',\n",
       "        'category_34_b', 'title_similarity'],\n",
       "       dtype='object'),\n",
       " Index(['paper_a', 'paper_b', 'label', 'title', 'year', 'venue', 'index',\n",
       "        'citations', 'abstract', 'category_0', 'category_1', 'category_2',\n",
       "        'category_3', 'category_4', 'category_5', 'category_6', 'category_7',\n",
       "        'category_8', 'category_9', 'category_10', 'category_11', 'category_12',\n",
       "        'category_13', 'category_14', 'category_15', 'category_16',\n",
       "        'category_17', 'category_18', 'category_19', 'category_20',\n",
       "        'category_21', 'category_22', 'category_23', 'category_24',\n",
       "        'category_25', 'category_26', 'category_27', 'category_28',\n",
       "        'category_29', 'category_30', 'category_31', 'category_32',\n",
       "        'category_33', 'category_34', 'title_b', 'year_b', 'venue_b', 'index_b',\n",
       "        'citations_b', 'abstract_b', 'category_0_b', 'category_1_b',\n",
       "        'category_2_b', 'category_3_b', 'category_4_b', 'category_5_b',\n",
       "        'category_6_b', 'category_7_b', 'category_8_b', 'category_9_b',\n",
       "        'category_10_b', 'category_11_b', 'category_12_b', 'category_13_b',\n",
       "        'category_14_b', 'category_15_b', 'category_16_b', 'category_17_b',\n",
       "        'category_18_b', 'category_19_b', 'category_20_b', 'category_21_b',\n",
       "        'category_22_b', 'category_23_b', 'category_24_b', 'category_25_b',\n",
       "        'category_26_b', 'category_27_b', 'category_28_b', 'category_29_b',\n",
       "        'category_30_b', 'category_31_b', 'category_32_b', 'category_33_b',\n",
       "        'category_34_b', 'title_similarity'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns, test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the columns that are not needed for features\n",
    "def preprocess_data(df):\n",
    "    features = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith('category'):\n",
    "            features.append(df[col].values)  # Category features\n",
    "    \n",
    "    # Add additional features (e.g., year, venue, title similarity)\n",
    "    features.append(df['year'].values)\n",
    "    features.append(df['venue'].values)\n",
    "    features.append(df['year_b'].values)\n",
    "    features.append(df['venue_b'].values)\n",
    "    features.append(df['title_similarity'].values)\n",
    "    \n",
    "    # Convert the features to a 2D array (each row is a paper pair)\n",
    "    features = np.column_stack(features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Step 2: Preprocess the raw train and test data\n",
    "X_train = preprocess_data(train_data)\n",
    "X_test = preprocess_data(test_data)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Calculate number of unique nodes\n",
    "num_nodes = len(pd.concat([train_data['paper_a'], train_data['paper_b']]).unique())\n",
    "\n",
    "# Step 4: Create edge_index\n",
    "def create_edge_index(data, num_nodes):\n",
    "    # Create a mapping from unique paper IDs to numeric indices (0, 1, 2,...)\n",
    "    paper_ids = pd.concat([data['paper_a'], data['paper_b']]).unique()\n",
    "    paper_id_map = {paper: idx for idx, paper in enumerate(paper_ids)}\n",
    "\n",
    "    # Replace paper_a and paper_b with their corresponding numeric IDs\n",
    "    edge_index = []\n",
    "    for i, row in data.iterrows():\n",
    "        if row['label'] == 1:  # Add an edge if there's a citation\n",
    "            paper_a_idx = paper_id_map[row['paper_a']]\n",
    "            paper_b_idx = paper_id_map[row['paper_b']]\n",
    "            \n",
    "            # Ensure the indices are valid\n",
    "            if paper_a_idx < num_nodes and paper_b_idx < num_nodes:\n",
    "                edge_index.append([paper_a_idx, paper_b_idx])  # Directed edge\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index_train = create_edge_index(train_data, num_nodes)\n",
    "edge_index_test = create_edge_index(test_data, num_nodes)\n",
    "\n",
    "# Step 5: Define a custom Dataset class for PyTorch Geometric\n",
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, edge_index):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)  # Return the number of data samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # For each sample, return a Data object (used by DataLoader)\n",
    "        data = Data(x=self.X[idx], edge_index=self.edge_index, y=self.y[idx])\n",
    "        return data\n",
    "\n",
    "# Convert the features to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)\n",
    "\n",
    "# Step 6: Create Dataset and DataLoader objects\n",
    "train_dataset = GraphDataset(X_train_tensor, y_train_tensor, edge_index_train)\n",
    "test_dataset = GraphDataset(X_test_tensor, y_test_tensor, edge_index_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_edge_index(edge_index, num_nodes):\n",
    "    # Check if any indices are out of range\n",
    "    if edge_index.max() >= num_nodes or edge_index.min() < 0:\n",
    "        print(f\"Error: edge_index contains out-of-range indices.\")\n",
    "        print(f\"Max index: {edge_index.max()}, Number of nodes: {num_nodes}\")\n",
    "        print(f\"Min index: {edge_index.min()}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Validate edge_index after creation\n",
    "if not validate_edge_index(edge_index_train, num_nodes):\n",
    "    print(\"Invalid edge_index in training data!\")\n",
    "if not validate_edge_index(edge_index_test, num_nodes):\n",
    "    print(\"Invalid edge_index in test data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Define the Improved Graph Neural Network model\n",
    "class ImprovedGCN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes=1, hidden_units=64, dropout_rate=0.5):\n",
    "        super(ImprovedGCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(num_node_features, hidden_units)\n",
    "        self.conv2 = GCNConv(hidden_units, hidden_units)\n",
    "        self.conv3 = GCNConv(hidden_units, num_classes)  # Third layer\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        return torch.sigmoid(x)  # Use sigmoid for binary classification\n",
    "\n",
    "def train_model(model, train_loader, epochs=50):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            # Debugging: Inspect the shapes\n",
    "            print(f\"Data.x shape: {data.x.shape}\")  # Expected to be [num_nodes, num_features]\n",
    "            print(f\"Data.edge_index shape: {data.edge_index.shape}\")  # Expected to be [2, num_edges]\n",
    "            \n",
    "            # Check for out-of-bounds indices in edge_index\n",
    "            if data.edge_index.max() >= data.x.size(0):\n",
    "                print(f\"Warning: edge_index contains indices larger than the number of nodes: {data.edge_index.max().item()} >= {data.x.size(0)}\")\n",
    "\n",
    "            # Ensure data.x is of shape (num_nodes, num_features)\n",
    "            if len(data.x.shape) == 1:\n",
    "                data.x = data.x.view(-1, 1)  # Reshape to (num_nodes, 1) if it's currently (num_features,)\n",
    "                print(f\"Reshaped Data.x shape: {data.x.shape}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data).squeeze()  # Squeeze to match the shape of the labels\n",
    "            loss = F.binary_cross_entropy(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Step 8: Evaluation function (with ROC Curve)\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data).squeeze()  # Squeeze to match the labels shape\n",
    "            pred = (out > 0.5).float()  # Convert to binary predictions (0 or 1)\n",
    "            all_preds.append(out)\n",
    "            all_labels.append(data.y)\n",
    "        \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = (all_preds.round() == all_labels).sum() / len(all_labels)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # ROC Curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Step 9: Initialize the Model, Optimizer, and Loss Function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ImprovedGCN(num_node_features=X_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data.x shape: torch.Size([9600])\n",
      "Data.edge_index shape: torch.Size([2, 6400000])\n",
      "Warning: edge_index contains indices larger than the number of nodes: 113776 >= 9600\n",
      "Reshaped Data.x shape: torch.Size([9600, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 35618 is out of bounds for dimension 0 with size 9600",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[103], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Step 10: Train the model\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Step 11: Evaluate on test set\u001b[39;00m\n\u001b[0;32m      5\u001b[0m evaluate_model(model, test_loader)\n",
      "Cell \u001b[1;32mIn[102], line 49\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, epochs)\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshaped Data.x shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 49\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Squeeze to match the shape of the labels\u001b[39;00m\n\u001b[0;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(out, data\u001b[38;5;241m.\u001b[39my)\n\u001b[0;32m     51\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\somma\\Tommaso\\D3A\\Data_challenge_ENT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\somma\\Tommaso\\D3A\\Data_challenge_ENT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[102], line 16\u001b[0m, in \u001b[0;36mImprovedGCN.forward\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m     13\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# First Convolutional Layer\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[0;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)  \u001b[38;5;66;03m# Apply dropout\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\somma\\Tommaso\\D3A\\Data_challenge_ENT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\somma\\Tommaso\\D3A\\Data_challenge_ENT\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\somma\\Tommaso\\D3A\\Data_challenge_ENT\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[1;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[0;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[0;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[0;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[1;32mc:\\Users\\somma\\Tommaso\\D3A\\Data_challenge_ENT\\.venv\\Lib\\site-packages\\torch_geometric\\nn\\conv\\gcn_conv.py:108\u001b[0m, in \u001b[0;36mgcn_norm\u001b[1;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m    107\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[1;32m--> 108\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    109\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m    110\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\somma\\Tommaso\\D3A\\Data_challenge_ENT\\.venv\\Lib\\site-packages\\torch_geometric\\utils\\_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[1;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[1;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: index 35618 is out of bounds for dimension 0 with size 9600"
     ]
    }
   ],
   "source": [
    "# Step 10: Train the model\n",
    "train_model(model, train_loader, epochs=50)\n",
    "\n",
    "# Step 11: Evaluate on test set\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.9715\n",
      "Epoch 10, Loss: 0.6665\n",
      "Epoch 20, Loss: 0.6163\n",
      "Epoch 30, Loss: 0.5951\n",
      "Epoch 40, Loss: 0.5834\n",
      "Epoch 50, Loss: 0.5752\n",
      "Epoch 60, Loss: 0.5692\n",
      "Epoch 70, Loss: 0.5646\n",
      "Epoch 80, Loss: 0.5608\n",
      "Epoch 90, Loss: 0.5574\n",
      "Epoch 100, Loss: 0.5547\n",
      "Epoch 110, Loss: 0.5522\n",
      "Epoch 120, Loss: 0.5502\n",
      "Epoch 130, Loss: 0.5486\n",
      "Epoch 140, Loss: 0.5473\n",
      "Epoch 150, Loss: 0.5462\n",
      "Epoch 160, Loss: 0.5452\n",
      "Epoch 170, Loss: 0.5443\n",
      "Epoch 180, Loss: 0.5435\n",
      "Epoch 190, Loss: 0.5428\n",
      "Epoch 200, Loss: 0.5421\n",
      "Epoch 210, Loss: 0.5415\n",
      "Epoch 220, Loss: 0.5409\n",
      "Epoch 230, Loss: 0.5403\n",
      "Epoch 240, Loss: 0.5397\n",
      "Epoch 250, Loss: 0.5392\n",
      "Epoch 260, Loss: 0.5387\n",
      "Epoch 270, Loss: 0.5382\n",
      "Epoch 280, Loss: 0.5378\n",
      "Epoch 290, Loss: 0.5374\n",
      "Epoch 300, Loss: 0.5371\n",
      "Epoch 310, Loss: 0.5367\n",
      "Epoch 320, Loss: 0.5364\n",
      "Epoch 330, Loss: 0.5361\n",
      "Epoch 340, Loss: 0.5359\n",
      "Epoch 350, Loss: 0.5356\n",
      "Epoch 360, Loss: 0.5354\n",
      "Epoch 370, Loss: 0.5351\n",
      "Epoch 380, Loss: 0.5349\n",
      "Epoch 390, Loss: 0.5347\n",
      "Epoch 400, Loss: 0.5345\n",
      "Epoch 410, Loss: 0.5343\n",
      "Epoch 420, Loss: 0.5340\n",
      "Epoch 430, Loss: 0.5337\n",
      "Epoch 440, Loss: 0.5334\n",
      "Epoch 450, Loss: 0.5330\n",
      "Epoch 460, Loss: 0.5327\n",
      "Epoch 470, Loss: 0.5324\n",
      "Epoch 480, Loss: 0.5320\n",
      "Epoch 490, Loss: 0.5316\n",
      "Epoch 500, Loss: 0.5312\n",
      "Epoch 510, Loss: 0.5308\n",
      "Epoch 520, Loss: 0.5302\n",
      "Epoch 530, Loss: 0.5297\n",
      "Epoch 540, Loss: 0.5292\n",
      "Epoch 550, Loss: 0.5288\n",
      "Epoch 560, Loss: 0.5283\n",
      "Epoch 570, Loss: 0.5279\n",
      "Epoch 580, Loss: 0.5275\n",
      "Epoch 590, Loss: 0.5271\n",
      "Epoch 600, Loss: 0.5268\n",
      "Epoch 610, Loss: 0.5264\n",
      "Epoch 620, Loss: 0.5260\n",
      "Epoch 630, Loss: 0.5257\n",
      "Epoch 640, Loss: 0.5254\n",
      "Epoch 650, Loss: 0.5252\n",
      "Epoch 660, Loss: 0.5250\n",
      "Epoch 670, Loss: 0.5249\n",
      "Epoch 680, Loss: 0.5247\n",
      "Epoch 690, Loss: 0.5246\n",
      "Epoch 700, Loss: 0.5244\n",
      "Epoch 710, Loss: 0.5243\n",
      "Epoch 720, Loss: 0.5242\n",
      "Epoch 730, Loss: 0.5240\n",
      "Epoch 740, Loss: 0.5239\n",
      "Epoch 750, Loss: 0.5238\n",
      "Epoch 760, Loss: 0.5237\n",
      "Epoch 770, Loss: 0.5236\n",
      "Epoch 780, Loss: 0.5235\n",
      "Epoch 790, Loss: 0.5234\n",
      "Epoch 800, Loss: 0.5233\n",
      "Epoch 810, Loss: 0.5231\n",
      "Epoch 820, Loss: 0.5231\n",
      "Epoch 830, Loss: 0.5230\n",
      "Epoch 840, Loss: 0.5229\n",
      "Epoch 850, Loss: 0.5228\n",
      "Epoch 860, Loss: 0.5228\n",
      "Epoch 870, Loss: 0.5227\n",
      "Epoch 880, Loss: 0.5226\n",
      "Epoch 890, Loss: 0.5225\n",
      "Epoch 900, Loss: 0.5225\n",
      "Epoch 910, Loss: 0.5224\n",
      "Epoch 920, Loss: 0.5223\n",
      "Epoch 930, Loss: 0.5222\n",
      "Epoch 940, Loss: 0.5221\n",
      "Epoch 950, Loss: 0.5221\n",
      "Epoch 960, Loss: 0.5220\n",
      "Epoch 970, Loss: 0.5220\n",
      "Epoch 980, Loss: 0.5219\n",
      "Epoch 990, Loss: 0.5219\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 1: Load Data\n",
    "train_data = pd.read_pickle('Data/train_dataset_title_sim.pkl')\n",
    "test_data = pd.read_pickle('Data/test_dataset_title_sim.pkl')\n",
    "\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Step 2: Preprocess Features\n",
    "def preprocess_data(df):\n",
    "    features = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith('category'):\n",
    "            features.append(df[col].values)  # Category features\n",
    "\n",
    "    # Add additional features\n",
    "    features.append(df['year'].values)\n",
    "    features.append(df['venue'].values)\n",
    "    features.append(df['year_b'].values)\n",
    "    features.append(df['venue_b'].values)\n",
    "    features.append(df['title_similarity'].values)\n",
    "\n",
    "    # Convert to 2D array\n",
    "    features = np.column_stack(features)\n",
    "    return features\n",
    "\n",
    "X_train = preprocess_data(train_data)\n",
    "X_test = preprocess_data(test_data)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Create Edge Indices\n",
    "def create_edge_index(data, num_nodes):\n",
    "    paper_ids = pd.concat([data['paper_a'], data['paper_b']]).unique()\n",
    "    paper_id_map = {paper: idx for idx, paper in enumerate(paper_ids)}\n",
    "\n",
    "    edge_index = []\n",
    "    for _, row in data.iterrows():\n",
    "        if row['label'] == 1:  # Add an edge for citation\n",
    "            paper_a_id = paper_id_map.get(row['paper_a'])\n",
    "            paper_b_id = paper_id_map.get(row['paper_b'])\n",
    "            if paper_a_id is not None and paper_b_id is not None:\n",
    "                if paper_a_id < num_nodes and paper_b_id < num_nodes:\n",
    "                    edge_index.append([paper_a_id, paper_b_id])\n",
    "\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "    # Validate edge indices\n",
    "    if edge_index.numel() > 0 and edge_index.max().item() >= num_nodes:\n",
    "        raise ValueError(\"Edge index contains out-of-bound indices!\")\n",
    "\n",
    "    return edge_index\n",
    "\n",
    "num_nodes_train = X_train.shape[0]\n",
    "num_nodes_test = X_test.shape[0]\n",
    "\n",
    "edge_index_train = create_edge_index(train_data, num_nodes=num_nodes_train)\n",
    "edge_index_test = create_edge_index(test_data, num_nodes=num_nodes_test)\n",
    "\n",
    "# Step 4: Create PyTorch Geometric Data Objects\n",
    "data_train = Data(\n",
    "    x=torch.tensor(X_train, dtype=torch.float),\n",
    "    edge_index=edge_index_train,\n",
    "    y=torch.tensor(y_train.values, dtype=torch.float)\n",
    ")\n",
    "\n",
    "data_test = Data(\n",
    "    x=torch.tensor(X_test, dtype=torch.float),\n",
    "    edge_index=edge_index_test,\n",
    "    y=torch.tensor(y_test.values, dtype=torch.float)\n",
    ")\n",
    "\n",
    "# Step 5: Define GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 1)  # Binary output\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return torch.sigmoid(x).squeeze()  # Binary probability output\n",
    "\n",
    "# Step 6: Train GCN Model\n",
    "def train_model(model, data, epochs=1000, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.binary_cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "# Step 7: Initialize and Train the Model\n",
    "gcn = GCN(num_node_features=X_train.shape[1])\n",
    "gcn = train_model(gcn, data_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7257\n",
      "Test Precision: 0.7198\n",
      "Test Recall: 0.7392\n",
      "Test F1 Score: 0.7294\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Step 8: Evaluate the Model\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Forward pass to get predictions\n",
    "        out = model(data)\n",
    "        predictions = (out >= 0.5).float()  # Apply threshold\n",
    "\n",
    "        # Compute metrics\n",
    "        y_true = data.y.cpu().numpy()\n",
    "        y_pred = predictions.cpu().numpy()\n",
    "\n",
    "        accuracy = accuracy_score(y_true, y_pred)\n",
    "        precision = precision_score(y_true, y_pred)\n",
    "        recall = recall_score(y_true, y_pred)\n",
    "        f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Perform evaluation on test data\n",
    "accuracy, precision, recall, f1 = evaluate_model(gcn, data_test)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Test Precision: {precision:.4f}\")\n",
    "print(f\"Test Recall: {recall:.4f}\")\n",
    "print(f\"Test F1 Score: {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results obtained seems to not be better than the normal models, probably these models need to be tuned better and they may be too simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
