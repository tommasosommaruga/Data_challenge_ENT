{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Graph NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_a</th>\n",
       "      <th>paper_b</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>category_0</th>\n",
       "      <th>...</th>\n",
       "      <th>category_26_b</th>\n",
       "      <th>category_27_b</th>\n",
       "      <th>category_28_b</th>\n",
       "      <th>category_29_b</th>\n",
       "      <th>category_30_b</th>\n",
       "      <th>category_31_b</th>\n",
       "      <th>category_32_b</th>\n",
       "      <th>category_33_b</th>\n",
       "      <th>category_34_b</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>223465</td>\n",
       "      <td>481995</td>\n",
       "      <td>0</td>\n",
       "      <td>Generation and transformation of interface tra...</td>\n",
       "      <td>1993</td>\n",
       "      <td>1</td>\n",
       "      <td>223465</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347910</td>\n",
       "      <td>291414</td>\n",
       "      <td>1</td>\n",
       "      <td>An integrated modelling framework to support m...</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>347910</td>\n",
       "      <td>110359;291414;593858;604335;433150</td>\n",
       "      <td>This paper proposes an integrated modelling fr...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.578392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>141221</td>\n",
       "      <td>422833</td>\n",
       "      <td>1</td>\n",
       "      <td>Bandit-based optimization on graphs with appli...</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>141221</td>\n",
       "      <td>104308;422833</td>\n",
       "      <td>The problem of choosing fast implementations f...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282962</td>\n",
       "      <td>229639</td>\n",
       "      <td>1</td>\n",
       "      <td>Completion time multiple branch prediction for...</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>282962</td>\n",
       "      <td>83477;85142;229639;289424;591931;591451;449247...</td>\n",
       "      <td>The need for multiple branch prediction is inh...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.426018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>598712</td>\n",
       "      <td>468674</td>\n",
       "      <td>1</td>\n",
       "      <td>Sample sizes for sigmoidal neural networks</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>598712</td>\n",
       "      <td>228084;457547;468674;486038;587976;600775</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.013893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_a paper_b  label                                              title  \\\n",
       "0  223465  481995      0  Generation and transformation of interface tra...   \n",
       "1  347910  291414      1  An integrated modelling framework to support m...   \n",
       "2  141221  422833      1  Bandit-based optimization on graphs with appli...   \n",
       "3  282962  229639      1  Completion time multiple branch prediction for...   \n",
       "4  598712  468674      1         Sample sizes for sigmoidal neural networks   \n",
       "\n",
       "   year  venue   index                                          citations  \\\n",
       "0  1993      1  223465                                               None   \n",
       "1  2008      1  347910                 110359;291414;593858;604335;433150   \n",
       "2  2009      1  141221                                      104308;422833   \n",
       "3  2000      1  282962  83477;85142;229639;289424;591931;591451;449247...   \n",
       "4  1995      1  598712          228084;457547;468674;486038;587976;600775   \n",
       "\n",
       "                                            abstract  category_0  ...  \\\n",
       "0                                               None           0  ...   \n",
       "1  This paper proposes an integrated modelling fr...           0  ...   \n",
       "2  The problem of choosing fast implementations f...           0  ...   \n",
       "3  The need for multiple branch prediction is inh...           0  ...   \n",
       "4                                               None           0  ...   \n",
       "\n",
       "   category_26_b  category_27_b  category_28_b  category_29_b  category_30_b  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   category_31_b  category_32_b  category_33_b  category_34_b  \\\n",
       "0              0              0              0              0   \n",
       "1              0              0              0              0   \n",
       "2              0              0              0              1   \n",
       "3              0              0              0              1   \n",
       "4              0              0              0              0   \n",
       "\n",
       "   title_similarity  \n",
       "0          0.000000  \n",
       "1          0.578392  \n",
       "2          0.000000  \n",
       "3          0.426018  \n",
       "4          0.013893  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_a</th>\n",
       "      <th>paper_b</th>\n",
       "      <th>label</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>index</th>\n",
       "      <th>citations</th>\n",
       "      <th>abstract</th>\n",
       "      <th>category_0</th>\n",
       "      <th>...</th>\n",
       "      <th>category_26_b</th>\n",
       "      <th>category_27_b</th>\n",
       "      <th>category_28_b</th>\n",
       "      <th>category_29_b</th>\n",
       "      <th>category_30_b</th>\n",
       "      <th>category_31_b</th>\n",
       "      <th>category_32_b</th>\n",
       "      <th>category_33_b</th>\n",
       "      <th>category_34_b</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119995</td>\n",
       "      <td>358509</td>\n",
       "      <td>0</td>\n",
       "      <td>An object-oriented framework for modular resou...</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>119995</td>\n",
       "      <td>None</td>\n",
       "      <td>The authors present a flexible object-oriented...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>391615</td>\n",
       "      <td>416623</td>\n",
       "      <td>1</td>\n",
       "      <td>Ispy: detecting ip prefix hijacking on my own</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>391615</td>\n",
       "      <td>21144;29093;49036;124539;338587;353602;416623;...</td>\n",
       "      <td>IP prefix hijacking remains a major threat to ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.518576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>123767</td>\n",
       "      <td>452007</td>\n",
       "      <td>1</td>\n",
       "      <td>Tellegen's principle into practice</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>123767</td>\n",
       "      <td>452007;460955;192531;287858;570231;286329;4877...</td>\n",
       "      <td>The transposition principle, also called Telle...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>311521</td>\n",
       "      <td>376606</td>\n",
       "      <td>1</td>\n",
       "      <td>Efficient region-based image retrieval</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>311521</td>\n",
       "      <td>174368;255539;291575;370858;366139;369052;3835...</td>\n",
       "      <td>Region-based image retrieval(RBIR) was recentl...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>341400</td>\n",
       "      <td>371412</td>\n",
       "      <td>1</td>\n",
       "      <td>BibFinder/StatMiner: effectively mining and us...</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>341400</td>\n",
       "      <td>371412;623744</td>\n",
       "      <td>Recent work in data integration has shown the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.318530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  paper_a paper_b  label                                              title  \\\n",
       "0  119995  358509      0  An object-oriented framework for modular resou...   \n",
       "1  391615  416623      1      Ispy: detecting ip prefix hijacking on my own   \n",
       "2  123767  452007      1                 Tellegen's principle into practice   \n",
       "3  311521  376606      1             Efficient region-based image retrieval   \n",
       "4  341400  371412      1  BibFinder/StatMiner: effectively mining and us...   \n",
       "\n",
       "   year  venue   index                                          citations  \\\n",
       "0  1996      1  119995                                               None   \n",
       "1  2008      1  391615  21144;29093;49036;124539;338587;353602;416623;...   \n",
       "2  2003      1  123767  452007;460955;192531;287858;570231;286329;4877...   \n",
       "3  2003      1  311521  174368;255539;291575;370858;366139;369052;3835...   \n",
       "4  2003      1  341400                                      371412;623744   \n",
       "\n",
       "                                            abstract  category_0  ...  \\\n",
       "0  The authors present a flexible object-oriented...           0  ...   \n",
       "1  IP prefix hijacking remains a major threat to ...           0  ...   \n",
       "2  The transposition principle, also called Telle...           0  ...   \n",
       "3  Region-based image retrieval(RBIR) was recentl...           0  ...   \n",
       "4  Recent work in data integration has shown the ...           0  ...   \n",
       "\n",
       "   category_26_b  category_27_b  category_28_b  category_29_b  category_30_b  \\\n",
       "0              0              0              0              0              0   \n",
       "1              0              0              0              0              0   \n",
       "2              0              0              0              0              0   \n",
       "3              0              0              0              0              0   \n",
       "4              0              0              0              0              0   \n",
       "\n",
       "   category_31_b  category_32_b  category_33_b  category_34_b  \\\n",
       "0              0              0              0              1   \n",
       "1              0              0              0              1   \n",
       "2              0              0              0              0   \n",
       "3              0              0              0              0   \n",
       "4              0              0              0              0   \n",
       "\n",
       "   title_similarity  \n",
       "0          0.000000  \n",
       "1          0.518576  \n",
       "2          0.000000  \n",
       "3          0.000000  \n",
       "4          0.318530  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_pickle('Data/train_dataset_title_sim.pkl')\n",
    "test_data = pd.read_pickle('Data/test_dataset_title_sim.pkl')\n",
    "train_labels = train_data['label']\n",
    "test_labels = test_data['label']\n",
    "\n",
    "# Display the first few rows of the training and testing datasets\n",
    "print(\"Training Data:\")\n",
    "display(train_data.head())\n",
    "print(\"\\nTesting Data:\")\n",
    "display(test_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_a</th>\n",
       "      <th>paper_b</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "      <th>category_5</th>\n",
       "      <th>...</th>\n",
       "      <th>category_26_b</th>\n",
       "      <th>category_27_b</th>\n",
       "      <th>category_28_b</th>\n",
       "      <th>category_29_b</th>\n",
       "      <th>category_30_b</th>\n",
       "      <th>category_31_b</th>\n",
       "      <th>category_32_b</th>\n",
       "      <th>category_33_b</th>\n",
       "      <th>category_34_b</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>139911</th>\n",
       "      <td>572478</td>\n",
       "      <td>518617</td>\n",
       "      <td>2002</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165378</th>\n",
       "      <td>500988</td>\n",
       "      <td>407451</td>\n",
       "      <td>2009</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16168</th>\n",
       "      <td>556680</td>\n",
       "      <td>607463</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56426</th>\n",
       "      <td>448817</td>\n",
       "      <td>189920</td>\n",
       "      <td>1995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.018672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163921</th>\n",
       "      <td>382278</td>\n",
       "      <td>440110</td>\n",
       "      <td>1997</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75522</th>\n",
       "      <td>299897</td>\n",
       "      <td>541129</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80764</th>\n",
       "      <td>441640</td>\n",
       "      <td>164950</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199012</th>\n",
       "      <td>441842</td>\n",
       "      <td>173093</td>\n",
       "      <td>1990</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.230021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182090</th>\n",
       "      <td>219361</td>\n",
       "      <td>184506</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126863</th>\n",
       "      <td>279833</td>\n",
       "      <td>96013</td>\n",
       "      <td>1999</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.531097</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paper_a paper_b  year  venue  category_0  category_1  category_2  \\\n",
       "139911  572478  518617  2002      1           0           0           0   \n",
       "165378  500988  407451  2009      1           0           0           0   \n",
       "16168   556680  607463  2000      1           0           0           0   \n",
       "56426   448817  189920  1995      1           0           0           0   \n",
       "163921  382278  440110  1997      1           0           0           0   \n",
       "...        ...     ...   ...    ...         ...         ...         ...   \n",
       "75522   299897  541129  1998      1           0           0           0   \n",
       "80764   441640  164950  2003      1           0           0           0   \n",
       "199012  441842  173093  1990      1           0           0           0   \n",
       "182090  219361  184506  1994      1           0           0           0   \n",
       "126863  279833   96013  1999      1           0           0           0   \n",
       "\n",
       "        category_3  category_4  category_5  ...  category_26_b  category_27_b  \\\n",
       "139911           0           0           0  ...              0              0   \n",
       "165378           0           0           0  ...              0              0   \n",
       "16168            0           0           0  ...              0              0   \n",
       "56426            0           0           0  ...              0              0   \n",
       "163921           0           0           0  ...              0              0   \n",
       "...            ...         ...         ...  ...            ...            ...   \n",
       "75522            0           0           0  ...              0              0   \n",
       "80764            0           0           0  ...              0              0   \n",
       "199012           0           0           0  ...              0              0   \n",
       "182090           0           0           0  ...              1              0   \n",
       "126863           0           0           0  ...              0              0   \n",
       "\n",
       "        category_28_b  category_29_b  category_30_b  category_31_b  \\\n",
       "139911              0              0              0              0   \n",
       "165378              0              0              0              0   \n",
       "16168               0              0              0              0   \n",
       "56426               0              0              0              0   \n",
       "163921              0              0              0              0   \n",
       "...               ...            ...            ...            ...   \n",
       "75522               0              0              0              0   \n",
       "80764               0              0              0              0   \n",
       "199012              0              1              0              0   \n",
       "182090              0              0              0              0   \n",
       "126863              0              0              0              0   \n",
       "\n",
       "        category_32_b  category_33_b  category_34_b  title_similarity  \n",
       "139911              0              0              0          0.000000  \n",
       "165378              0              0              0          0.000000  \n",
       "16168               0              0              0          0.000000  \n",
       "56426               0              0              0          0.018672  \n",
       "163921              0              0              0          0.000000  \n",
       "...               ...            ...            ...               ...  \n",
       "75522               0              0              1          0.000000  \n",
       "80764               0              0              1          0.000000  \n",
       "199012              0              0              0          0.230021  \n",
       "182090              0              0              0          0.248013  \n",
       "126863              0              0              1          0.531097  \n",
       "\n",
       "[1000 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_a</th>\n",
       "      <th>paper_b</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>category_0</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "      <th>category_4</th>\n",
       "      <th>category_5</th>\n",
       "      <th>...</th>\n",
       "      <th>category_26_b</th>\n",
       "      <th>category_27_b</th>\n",
       "      <th>category_28_b</th>\n",
       "      <th>category_29_b</th>\n",
       "      <th>category_30_b</th>\n",
       "      <th>category_31_b</th>\n",
       "      <th>category_32_b</th>\n",
       "      <th>category_33_b</th>\n",
       "      <th>category_34_b</th>\n",
       "      <th>title_similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43951</th>\n",
       "      <td>520679</td>\n",
       "      <td>252816</td>\n",
       "      <td>1992</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.025307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39639</th>\n",
       "      <td>119748</td>\n",
       "      <td>244891</td>\n",
       "      <td>2003</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.012532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40630</th>\n",
       "      <td>578083</td>\n",
       "      <td>165339</td>\n",
       "      <td>2005</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25198</th>\n",
       "      <td>3579</td>\n",
       "      <td>628759</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49256</th>\n",
       "      <td>406627</td>\n",
       "      <td>164979</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42670</th>\n",
       "      <td>392499</td>\n",
       "      <td>91363</td>\n",
       "      <td>2006</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.253257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8976</th>\n",
       "      <td>463002</td>\n",
       "      <td>150387</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21620</th>\n",
       "      <td>45304</td>\n",
       "      <td>296283</td>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.120208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46461</th>\n",
       "      <td>287971</td>\n",
       "      <td>163009</td>\n",
       "      <td>1994</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.175088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20486</th>\n",
       "      <td>298026</td>\n",
       "      <td>484187</td>\n",
       "      <td>1998</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      paper_a paper_b  year  venue  category_0  category_1  category_2  \\\n",
       "43951  520679  252816  1992      1           0           0           0   \n",
       "39639  119748  244891  2003      1           0           0           0   \n",
       "40630  578083  165339  2005      0           0           0           0   \n",
       "25198    3579  628759  1998      0           0           0           0   \n",
       "49256  406627  164979  2008      1           0           0           0   \n",
       "...       ...     ...   ...    ...         ...         ...         ...   \n",
       "42670  392499   91363  2006      1           0           1           0   \n",
       "8976   463002  150387  1988      1           0           0           0   \n",
       "21620   45304  296283  2008      1           0           0           0   \n",
       "46461  287971  163009  1994      1           1           0           0   \n",
       "20486  298026  484187  1998      1           0           0           0   \n",
       "\n",
       "       category_3  category_4  category_5  ...  category_26_b  category_27_b  \\\n",
       "43951           0           0           0  ...              0              0   \n",
       "39639           0           0           0  ...              0              0   \n",
       "40630           1           0           0  ...              0              0   \n",
       "25198           0           0           0  ...              0              0   \n",
       "49256           0           0           0  ...              0              0   \n",
       "...           ...         ...         ...  ...            ...            ...   \n",
       "42670           1           0           0  ...              0              0   \n",
       "8976            0           0           0  ...              0              0   \n",
       "21620           0           0           0  ...              0              0   \n",
       "46461           0           0           0  ...              0              0   \n",
       "20486           0           0           1  ...              0              0   \n",
       "\n",
       "       category_28_b  category_29_b  category_30_b  category_31_b  \\\n",
       "43951              0              0              0              0   \n",
       "39639              0              0              0              0   \n",
       "40630              0              0              0              0   \n",
       "25198              0              0              1              0   \n",
       "49256              0              0              0              0   \n",
       "...              ...            ...            ...            ...   \n",
       "42670              0              0              0              0   \n",
       "8976               0              0              0              0   \n",
       "21620              0              0              0              0   \n",
       "46461              0              0              0              0   \n",
       "20486              0              0              0              0   \n",
       "\n",
       "       category_32_b  category_33_b  category_34_b  title_similarity  \n",
       "43951              0              0              0          0.025307  \n",
       "39639              0              0              0          0.012532  \n",
       "40630              0              0              1          0.000000  \n",
       "25198              0              0              0          0.000000  \n",
       "49256              0              0              1          0.000000  \n",
       "...              ...            ...            ...               ...  \n",
       "42670              0              0              0          0.253257  \n",
       "8976               0              0              0          0.561113  \n",
       "21620              0              0              1          0.120208  \n",
       "46461              0              0              0          0.175088  \n",
       "20486              0              0              1          0.000000  \n",
       "\n",
       "[1000 rows x 81 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution in training data:\n",
      "label\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n",
      "Label distribution in testing data:\n",
      "label\n",
      "0    500\n",
      "1    500\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming train_data and test_data are already defined DataFrames\n",
    "\n",
    "# Function to create a balanced dataset\n",
    "def create_balanced_dataset(data, n_per_class=500):\n",
    "    # Separate the data into two groups based on the 'label'\n",
    "    group_0 = data[data['label'] == 0]\n",
    "    group_1 = data[data['label'] == 1]\n",
    "\n",
    "    # Randomly sample n_per_class rows from each group\n",
    "    sampled_group_0 = group_0.sample(n=n_per_class, random_state=55)  # Set random_state for reproducibility\n",
    "    sampled_group_1 = group_1.sample(n=n_per_class, random_state=55)\n",
    "\n",
    "    # Combine the sampled groups to create a balanced dataset\n",
    "    balanced_data = pd.concat([sampled_group_0, sampled_group_1])\n",
    "    \n",
    "    return balanced_data\n",
    "\n",
    "# Create balanced training dataset\n",
    "balanced_train_data = create_balanced_dataset(train_data, n_per_class=500)\n",
    "\n",
    "# Drop the specified columns from the training dataset\n",
    "X_train = balanced_train_data.drop(columns=['title', 'abstract', 'citations', 'index', 'label'])\n",
    "y_train = balanced_train_data['label']\n",
    "\n",
    "# Create balanced testing dataset\n",
    "balanced_test_data = create_balanced_dataset(test_data, n_per_class=500)\n",
    "\n",
    "# Drop the specified columns from the testing dataset\n",
    "X_test = balanced_test_data.drop(columns=['title', 'abstract', 'citations', 'index', 'label'])\n",
    "y_test = balanced_test_data['label']\n",
    "\n",
    "# Display the first few rows of the training and testing datasets\n",
    "print(\"Training Data:\")\n",
    "display(X_train)\n",
    "\n",
    "print(\"Testing Data:\")\n",
    "display(X_test)\n",
    "\n",
    "# Optionally, check the balance of the labels in the training and testing sets\n",
    "print(\"Label distribution in training data:\")\n",
    "print(y_train.value_counts())\n",
    "\n",
    "print(\"Label distribution in testing data:\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "def create_graph(pairs_df):\n",
    "    G = nx.DiGraph()  # Directed graph\n",
    "    for _, row in pairs_df.iterrows():\n",
    "        # Add nodes for paper_a and paper_b\n",
    "        G.add_node(row['paper_a'], features=row[['year'] + ['venue'] + [f'category_{i}' for i in range(35)]].to_dict())\n",
    "        G.add_node(row['paper_b'], features=row[['year_b'] + ['venue_b'] + [f'category_{i}_b' for i in range(35)]].to_dict())\n",
    "        \n",
    "        # Add edge from paper_a to paper_b\n",
    "        G.add_edge(row['paper_a'], row['paper_b'], label=row['label'])\n",
    "    \n",
    "    return G\n",
    "\n",
    "# Create training and testing graphs\n",
    "# train_graph = create_graph(train_data)\n",
    "# test_graph = create_graph(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#len(train_graph.nodes), len(train_graph.edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Step 1: Load and Prepare Data\n",
    "train_data = pd.read_pickle('Data/train_dataset_title_sim.pkl')\n",
    "test_data = pd.read_pickle('Data/test_dataset_title_sim.pkl')\n",
    "\n",
    "X_train_raw = train_data.drop(columns=['title', 'title_b', 'abstract', 'abstract_b', 'citations', 'citations_b', 'index', 'index_b', 'label'])\n",
    "y_train = train_data['label']\n",
    "X_test_raw = test_data.drop(columns=['title', 'title_b', 'abstract', 'abstract_b', 'citations', 'citations_b', 'index', 'index_b', 'label'])\n",
    "y_test = test_data['label']\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train_raw)\n",
    "X_test = scaler.transform(X_test_raw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['paper_a', 'paper_b', 'year', 'venue', 'category_0', 'category_1',\n",
       "       'category_2', 'category_3', 'category_4', 'category_5', 'category_6',\n",
       "       'category_7', 'category_8', 'category_9', 'category_10', 'category_11',\n",
       "       'category_12', 'category_13', 'category_14', 'category_15',\n",
       "       'category_16', 'category_17', 'category_18', 'category_19',\n",
       "       'category_20', 'category_21', 'category_22', 'category_23',\n",
       "       'category_24', 'category_25', 'category_26', 'category_27',\n",
       "       'category_28', 'category_29', 'category_30', 'category_31',\n",
       "       'category_32', 'category_33', 'category_34', 'year_b', 'venue_b',\n",
       "       'category_0_b', 'category_1_b', 'category_2_b', 'category_3_b',\n",
       "       'category_4_b', 'category_5_b', 'category_6_b', 'category_7_b',\n",
       "       'category_8_b', 'category_9_b', 'category_10_b', 'category_11_b',\n",
       "       'category_12_b', 'category_13_b', 'category_14_b', 'category_15_b',\n",
       "       'category_16_b', 'category_17_b', 'category_18_b', 'category_19_b',\n",
       "       'category_20_b', 'category_21_b', 'category_22_b', 'category_23_b',\n",
       "       'category_24_b', 'category_25_b', 'category_26_b', 'category_27_b',\n",
       "       'category_28_b', 'category_29_b', 'category_30_b', 'category_31_b',\n",
       "       'category_32_b', 'category_33_b', 'category_34_b', 'title_similarity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_edge_index(data):\n",
    "    # Create a mapping from unique paper IDs to numeric IDs\n",
    "    paper_ids = pd.concat([data['paper_a'], data['paper_b']]).unique()\n",
    "    paper_id_map = {paper: idx for idx, paper in enumerate(paper_ids)}\n",
    "\n",
    "    # Replace paper_a and paper_b with their corresponding numeric IDs\n",
    "    edge_index = []\n",
    "    for i, row in data.iterrows():\n",
    "        if row['label'] == 1:  # Add an edge if there's a citation\n",
    "            edge_index.append([paper_id_map[row['paper_a']], paper_id_map[row['paper_b']]])  # Directed edge\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "\n",
    "edge_index_train = create_edge_index(train_data)\n",
    "edge_index_test = create_edge_index(test_data)\n",
    "\n",
    "# Step 3: Prepare PyTorch Geometric Data Objects\n",
    "data_train = Data(x=torch.tensor(X_train, dtype=torch.float),\n",
    "                  edge_index=edge_index_train,\n",
    "                  y=torch.tensor(y_train.values, dtype=torch.float))  # Binary target\n",
    "\n",
    "data_test = Data(x=torch.tensor(X_test, dtype=torch.float),\n",
    "                 edge_index=edge_index_test,\n",
    "                 y=torch.tensor(y_test.values, dtype=torch.float))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Data(x=[200000, 77], edge_index=[2, 100000], y=[200000]),\n",
       " Data(x=[49936, 77], edge_index=[2, 24936], y=[49936]))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train, data_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define GCN Model\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, 1)  # Binary output\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return torch.sigmoid(x).squeeze()  # Binary probability output\n",
    "\n",
    "# Step 5: Train GCN Model\n",
    "def train_model(model, data, epochs=1000, lr=0.01):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.binary_cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "# Initialize and train GCN\n",
    "#gcn = GCN(num_node_features=X_train.shape[1])\n",
    "#gcn = train_model(gcn, data_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GCN:\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Evaluate GCN Model\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data)\n",
    "        predictions = (out > 0.5).float()  # Convert probabilities to binary predictions\n",
    "        accuracy = (predictions == data.y).sum().item() / len(data.y)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        return predictions\n",
    "\n",
    "print(\"\\nEvaluating GCN:\")\n",
    "#gcn_predictions = evaluate_model(gcn, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class ImprovedGCN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes, hidden_units=64, dropout_rate=0.5):\n",
    "        super(ImprovedGCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(num_node_features, hidden_units)\n",
    "        self.conv2 = GCNConv(hidden_units, hidden_units)\n",
    "        self.conv3 = GCNConv(hidden_units, num_classes)  # Third layer\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        return torch.sigmoid(x)  # Use sigmoid for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data, epochs=100, lr=0.01, patience=10):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "    best_loss = float('inf')\n",
    "    counter = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data).squeeze()  # Squeeze to match the shape of the labels\n",
    "        loss = F.binary_cross_entropy(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Early stopping check\n",
    "        if loss.item() < best_loss:\n",
    "            best_loss = loss.item()\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter > patience:\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(model, data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        out = model(data).squeeze()  # Squeeze to match the labels shape\n",
    "        pred = (out > 0.5).float()  # Convert to binary predictions (0 or 1)\n",
    "        \n",
    "        # Compute accuracy\n",
    "        accuracy = (pred == data.y).sum().item() / len(data.y)\n",
    "        print(f\"Accuracy: {accuracy:.4f}\")\n",
    "        \n",
    "        return out, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.8284\n",
      "Epoch 10, Loss: 0.6670\n",
      "Epoch 20, Loss: 0.6221\n",
      "Epoch 30, Loss: 0.5923\n",
      "Epoch 40, Loss: 0.5761\n",
      "Epoch 50, Loss: 0.5649\n",
      "Epoch 60, Loss: 0.5564\n",
      "Epoch 70, Loss: 0.5489\n",
      "Epoch 80, Loss: 0.5429\n",
      "Epoch 90, Loss: 0.5393\n",
      "Epoch 100, Loss: 0.5355\n",
      "Epoch 110, Loss: 0.5328\n",
      "Epoch 120, Loss: 0.5300\n",
      "Epoch 130, Loss: 0.5275\n",
      "Epoch 140, Loss: 0.5253\n",
      "Epoch 150, Loss: 0.5236\n",
      "Epoch 160, Loss: 0.5233\n",
      "Epoch 170, Loss: 0.5224\n",
      "Epoch 180, Loss: 0.5209\n",
      "Epoch 190, Loss: 0.5208\n",
      "Epoch 200, Loss: 0.5194\n",
      "Epoch 210, Loss: 0.5192\n",
      "Epoch 220, Loss: 0.5182\n",
      "Epoch 230, Loss: 0.5178\n",
      "Epoch 240, Loss: 0.5178\n",
      "Epoch 250, Loss: 0.5167\n",
      "Epoch 260, Loss: 0.5168\n",
      "Epoch 270, Loss: 0.5158\n",
      "Epoch 280, Loss: 0.5156\n",
      "Epoch 290, Loss: 0.5158\n",
      "Epoch 300, Loss: 0.5158\n",
      "Epoch 310, Loss: 0.5156\n",
      "Epoch 320, Loss: 0.5157\n",
      "Early stopping at epoch 328\n"
     ]
    }
   ],
   "source": [
    "# Initialize and train the Improved GCN\n",
    "#gcn = ImprovedGCN(num_node_features=X_train.shape[1], num_classes=1)\n",
    "#gcn = train_model(gcn, data_train, epochs=1000, lr=0.005, patience=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating GCN:\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nEvaluating GCN:\")\n",
    "#gcn_predictions = evaluate_model(gcn, data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not really improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying new method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Load and Prepare Data\n",
    "train_data = pd.read_pickle('Data/train_dataset_title_sim.pkl')\n",
    "test_data = pd.read_pickle('Data/test_dataset_title_sim.pkl')\n",
    "\n",
    "# Extracting the label column\n",
    "y_train = train_data['label']\n",
    "y_test = test_data['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['paper_a', 'paper_b', 'label', 'title', 'year', 'venue', 'index',\n",
       "        'citations', 'abstract', 'category_0', 'category_1', 'category_2',\n",
       "        'category_3', 'category_4', 'category_5', 'category_6', 'category_7',\n",
       "        'category_8', 'category_9', 'category_10', 'category_11', 'category_12',\n",
       "        'category_13', 'category_14', 'category_15', 'category_16',\n",
       "        'category_17', 'category_18', 'category_19', 'category_20',\n",
       "        'category_21', 'category_22', 'category_23', 'category_24',\n",
       "        'category_25', 'category_26', 'category_27', 'category_28',\n",
       "        'category_29', 'category_30', 'category_31', 'category_32',\n",
       "        'category_33', 'category_34', 'title_b', 'year_b', 'venue_b', 'index_b',\n",
       "        'citations_b', 'abstract_b', 'category_0_b', 'category_1_b',\n",
       "        'category_2_b', 'category_3_b', 'category_4_b', 'category_5_b',\n",
       "        'category_6_b', 'category_7_b', 'category_8_b', 'category_9_b',\n",
       "        'category_10_b', 'category_11_b', 'category_12_b', 'category_13_b',\n",
       "        'category_14_b', 'category_15_b', 'category_16_b', 'category_17_b',\n",
       "        'category_18_b', 'category_19_b', 'category_20_b', 'category_21_b',\n",
       "        'category_22_b', 'category_23_b', 'category_24_b', 'category_25_b',\n",
       "        'category_26_b', 'category_27_b', 'category_28_b', 'category_29_b',\n",
       "        'category_30_b', 'category_31_b', 'category_32_b', 'category_33_b',\n",
       "        'category_34_b', 'title_similarity'],\n",
       "       dtype='object'),\n",
       " Index(['paper_a', 'paper_b', 'label', 'title', 'year', 'venue', 'index',\n",
       "        'citations', 'abstract', 'category_0', 'category_1', 'category_2',\n",
       "        'category_3', 'category_4', 'category_5', 'category_6', 'category_7',\n",
       "        'category_8', 'category_9', 'category_10', 'category_11', 'category_12',\n",
       "        'category_13', 'category_14', 'category_15', 'category_16',\n",
       "        'category_17', 'category_18', 'category_19', 'category_20',\n",
       "        'category_21', 'category_22', 'category_23', 'category_24',\n",
       "        'category_25', 'category_26', 'category_27', 'category_28',\n",
       "        'category_29', 'category_30', 'category_31', 'category_32',\n",
       "        'category_33', 'category_34', 'title_b', 'year_b', 'venue_b', 'index_b',\n",
       "        'citations_b', 'abstract_b', 'category_0_b', 'category_1_b',\n",
       "        'category_2_b', 'category_3_b', 'category_4_b', 'category_5_b',\n",
       "        'category_6_b', 'category_7_b', 'category_8_b', 'category_9_b',\n",
       "        'category_10_b', 'category_11_b', 'category_12_b', 'category_13_b',\n",
       "        'category_14_b', 'category_15_b', 'category_16_b', 'category_17_b',\n",
       "        'category_18_b', 'category_19_b', 'category_20_b', 'category_21_b',\n",
       "        'category_22_b', 'category_23_b', 'category_24_b', 'category_25_b',\n",
       "        'category_26_b', 'category_27_b', 'category_28_b', 'category_29_b',\n",
       "        'category_30_b', 'category_31_b', 'category_32_b', 'category_33_b',\n",
       "        'category_34_b', 'title_similarity'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.columns, test_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remove the columns that are not needed for features\n",
    "def preprocess_data(df):\n",
    "    features = []\n",
    "    for col in df.columns:\n",
    "        if col.startswith('category'):\n",
    "            features.append(df[col].values)  # Category features\n",
    "    \n",
    "    # Add additional features (e.g., year, venue, title similarity)\n",
    "    features.append(df['year'].values)\n",
    "    features.append(df['venue'].values)\n",
    "    features.append(df['year_b'].values)\n",
    "    features.append(df['venue_b'].values)\n",
    "    features.append(df['title_similarity'].values)\n",
    "    \n",
    "    # Convert the features to a 2D array (each row is a paper pair)\n",
    "    features = np.column_stack(features)\n",
    "    \n",
    "    return features\n",
    "\n",
    "# Step 2: Preprocess the raw train and test data\n",
    "X_train = preprocess_data(train_data)\n",
    "X_test = preprocess_data(test_data)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Step 3: Calculate number of unique nodes\n",
    "num_nodes = len(pd.concat([train_data['paper_a'], train_data['paper_b']]).unique())\n",
    "\n",
    "# Step 4: Create edge_index\n",
    "def create_edge_index(data, num_nodes):\n",
    "    # Create a mapping from unique paper IDs to numeric indices (0, 1, 2,...)\n",
    "    paper_ids = pd.concat([data['paper_a'], data['paper_b']]).unique()\n",
    "    paper_id_map = {paper: idx for idx, paper in enumerate(paper_ids)}\n",
    "\n",
    "    # Replace paper_a and paper_b with their corresponding numeric IDs\n",
    "    edge_index = []\n",
    "    for i, row in data.iterrows():\n",
    "        if row['label'] == 1:  # Add an edge if there's a citation\n",
    "            paper_a_idx = paper_id_map[row['paper_a']]\n",
    "            paper_b_idx = paper_id_map[row['paper_b']]\n",
    "            \n",
    "            # Ensure the indices are valid\n",
    "            if paper_a_idx < num_nodes and paper_b_idx < num_nodes:\n",
    "                edge_index.append([paper_a_idx, paper_b_idx])  # Directed edge\n",
    "    return torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "\n",
    "edge_index_train = create_edge_index(train_data, num_nodes)\n",
    "edge_index_test = create_edge_index(test_data, num_nodes)\n",
    "\n",
    "# Step 5: Define a custom Dataset class for PyTorch Geometric\n",
    "class GraphDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y, edge_index):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.edge_index = edge_index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)  # Return the number of data samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # For each sample, return a Data object (used by DataLoader)\n",
    "        data = Data(x=self.X[idx], edge_index=self.edge_index, y=self.y[idx])\n",
    "        return data\n",
    "\n",
    "# Convert the features to torch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.float)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float)\n",
    "\n",
    "# Step 6: Create Dataset and DataLoader objects\n",
    "train_dataset = GraphDataset(X_train_tensor, y_train_tensor, edge_index_train)\n",
    "test_dataset = GraphDataset(X_test_tensor, y_test_tensor, edge_index_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_edge_index(edge_index, num_nodes):\n",
    "    # Check if any indices are out of range\n",
    "    if edge_index.max() >= num_nodes or edge_index.min() < 0:\n",
    "        print(f\"Error: edge_index contains out-of-range indices.\")\n",
    "        print(f\"Max index: {edge_index.max()}, Number of nodes: {num_nodes}\")\n",
    "        print(f\"Min index: {edge_index.min()}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "# Validate edge_index after creation\n",
    "if not validate_edge_index(edge_index_train, num_nodes):\n",
    "    print(\"Invalid edge_index in training data!\")\n",
    "if not validate_edge_index(edge_index_test, num_nodes):\n",
    "    print(\"Invalid edge_index in test data!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: Define the Improved Graph Neural Network model\n",
    "class ImprovedGCN(nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes=1, hidden_units=64, dropout_rate=0.5):\n",
    "        super(ImprovedGCN, self).__init__()\n",
    "        \n",
    "        self.conv1 = GCNConv(num_node_features, hidden_units)\n",
    "        self.conv2 = GCNConv(hidden_units, hidden_units)\n",
    "        self.conv3 = GCNConv(hidden_units, num_classes)  # Third layer\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        \n",
    "        # First Convolutional Layer\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)  # Apply dropout\n",
    "        \n",
    "        # Second Convolutional Layer\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        # Third Convolutional Layer\n",
    "        x = self.conv3(x, edge_index)\n",
    "        \n",
    "        return torch.sigmoid(x)  # Use sigmoid for binary classification\n",
    "\n",
    "def train_model(model, train_loader, epochs=50):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for data in train_loader:\n",
    "            # Debugging: Inspect the shapes\n",
    "            print(f\"Data.x shape: {data.x.shape}\")  # Expected to be [num_nodes, num_features]\n",
    "            print(f\"Data.edge_index shape: {data.edge_index.shape}\")  # Expected to be [2, num_edges]\n",
    "            \n",
    "            # Check for out-of-bounds indices in edge_index\n",
    "            if data.edge_index.max() >= data.x.size(0):\n",
    "                print(f\"Warning: edge_index contains indices larger than the number of nodes: {data.edge_index.max().item()} >= {data.x.size(0)}\")\n",
    "\n",
    "            # Ensure data.x is of shape (num_nodes, num_features)\n",
    "            if len(data.x.shape) == 1:\n",
    "                data.x = data.x.view(-1, 1)  # Reshape to (num_nodes, 1) if it's currently (num_features,)\n",
    "                print(f\"Reshaped Data.x shape: {data.x.shape}\")\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            out = model(data).squeeze()  # Squeeze to match the shape of the labels\n",
    "            loss = F.binary_cross_entropy(out, data.y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Step 8: Evaluation function (with ROC Curve)\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            out = model(data).squeeze()  # Squeeze to match the labels shape\n",
    "            pred = (out > 0.5).float()  # Convert to binary predictions (0 or 1)\n",
    "            all_preds.append(out)\n",
    "            all_labels.append(data.y)\n",
    "        \n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    \n",
    "    # Compute accuracy\n",
    "    accuracy = (all_preds.round() == all_labels).sum() / len(all_labels)\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    \n",
    "    # ROC Curve and AUC\n",
    "    fpr, tpr, _ = roc_curve(all_labels, all_preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    print(f\"AUC: {roc_auc:.4f}\")\n",
    "    \n",
    "    # Plot ROC curve\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "# Step 9: Initialize the Model, Optimizer, and Loss Function\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = ImprovedGCN(num_node_features=X_train.shape[1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data.x shape: torch.Size([9600])\n",
      "Data.edge_index shape: torch.Size([2, 12800000])\n",
      "Warning: edge_index contains indices larger than the number of nodes: 188434 >= 9600\n",
      "Reshaped Data.x shape: torch.Size([9600, 1])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "index 68927 is out of bounds for dimension 0 with size 9600",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Step 10: Train the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Step 11: Evaluate on test set\u001b[39;00m\n\u001b[1;32m      5\u001b[0m evaluate_model(model, test_loader)\n",
      "Cell \u001b[0;32mIn[147], line 49\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, epochs)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshaped Data.x shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 49\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze()  \u001b[38;5;66;03m# Squeeze to match the shape of the labels\u001b[39;00m\n\u001b[1;32m     50\u001b[0m loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mbinary_cross_entropy(out, data\u001b[38;5;241m.\u001b[39my)\n\u001b[1;32m     51\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/D3A/Data_challenge_3/Data_challenge_ENT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/D3A/Data_challenge_3/Data_challenge_ENT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[147], line 16\u001b[0m, in \u001b[0;36mImprovedGCN.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     13\u001b[0m x, edge_index \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mx, data\u001b[38;5;241m.\u001b[39medge_index\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# First Convolutional Layer\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)  \u001b[38;5;66;03m# Apply dropout\u001b[39;00m\n",
      "File \u001b[0;32m~/D3A/Data_challenge_3/Data_challenge_ENT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/D3A/Data_challenge_3/Data_challenge_ENT/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/D3A/Data_challenge_3/Data_challenge_ENT/.venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/D3A/Data_challenge_3/Data_challenge_ENT/.venv/lib/python3.11/site-packages/torch_geometric/nn/conv/gcn_conv.py:108\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m    106\u001b[0m row, col \u001b[38;5;241m=\u001b[39m edge_index[\u001b[38;5;241m0\u001b[39m], edge_index[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    107\u001b[0m idx \u001b[38;5;241m=\u001b[39m col \u001b[38;5;28;01mif\u001b[39;00m flow \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msource_to_target\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m row\n\u001b[0;32m--> 108\u001b[0m deg \u001b[38;5;241m=\u001b[39m \u001b[43mscatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_nodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduce\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msum\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m deg_inv_sqrt \u001b[38;5;241m=\u001b[39m deg\u001b[38;5;241m.\u001b[39mpow_(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[1;32m    110\u001b[0m deg_inv_sqrt\u001b[38;5;241m.\u001b[39mmasked_fill_(deg_inv_sqrt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/D3A/Data_challenge_3/Data_challenge_ENT/.venv/lib/python3.11/site-packages/torch_geometric/utils/_scatter.py:75\u001b[0m, in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     74\u001b[0m     index \u001b[38;5;241m=\u001b[39m broadcast(index, src, dim)\n\u001b[0;32m---> 75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msrc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_zeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_add_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m reduce \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     78\u001b[0m     count \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mnew_zeros(dim_size)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: index 68927 is out of bounds for dimension 0 with size 9600"
     ]
    }
   ],
   "source": [
    "# Step 10: Train the model\n",
    "train_model(model, train_loader, epochs=50)\n",
    "\n",
    "# Step 11: Evaluate on test set\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
